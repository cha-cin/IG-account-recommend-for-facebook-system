{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preference_Similarity_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import nltk\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import jieba.analyse\n",
    "import codecs\n",
    "from nltk.corpus import stopwords \n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import scipy as sp\n",
    "from scipy.stats import entropy\n",
    "from scipy.spatial import distance\n",
    "from numpy.linalg import norm\n",
    "import datetime\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 全域變數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variable\n",
    "#4大模組\n",
    "Prm = 0\n",
    "Pic = 0\n",
    "Pop = 0\n",
    "Act = 0\n",
    "#activate module\n",
    "#用戶發布的post數量\n",
    "Ap = 0\n",
    "#用戶最近一個月的post數量\n",
    "Apm = 0\n",
    "#用戶最新一次po文在多久以前\n",
    "Apt = None\n",
    "#用戶追蹤了多少人\n",
    "Af = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ig與fb 圖片的相似度分數\n",
    "ig_fb_picture_similarity_score_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #去除空值row\n",
    "oringnal_df = oringnal_df.dropna(subset=[\"message\"])\n",
    "oringnal_ig_df = oringnal_ig_df.dropna(subset=[\"post content\"])\n",
    "oringnal_df['new'] = \"NEW\"\n",
    "oringnal_ig_df['new content'] = \"None\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 文字前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 移除停留詞\n",
    "file_name = 'dictionary/stopword.txt'\n",
    "with open(file_name,'r',encoding=\"utf-8\") as f:\n",
    "    stop_words = f.readlines()\n",
    "def cut_words(text):\n",
    "    #斷詞 精準模式\n",
    "    text = jieba.cut(text, cut_all=False)\n",
    "    return text  \n",
    "def remove_stop_words(file_name,seg_list):\n",
    "    new_list = []\n",
    "    English_re = re.compile(r'[A-Za-z]')\n",
    "    Number_re = re.compile(r'[0-9]')\n",
    "    emoji_re = re.compile(\"[\\u4e00-\\u9FFF]\")\n",
    "    global stop_words\n",
    "    stop_words = [stop_word.rstrip() for stop_word in stop_words]\n",
    "    for seg in seg_list:\n",
    "        if seg not in stop_words:\n",
    "            #去除含有數字、英文、空格的元素\n",
    "            if (seg.isdigit() is True or seg is ' ' or bool(re.match(English_re, seg)) is True or bool(re.match(Number_re, seg)) is True or bool(re.match(emoji_re, seg)) is False):\n",
    "                continue\n",
    "            else:\n",
    "                #關鍵詞，去除停用字 (提高準確度!!!!!!!)\n",
    "                seg = jieba.analyse.extract_tags(seg, topK=20, withWeight=False, allowPOS=())\n",
    "#                 print(' '.join(seg))\n",
    "                new_list.append(' '.join(seg))\n",
    "            #if bool(re.match(my_re,seg)) is False and seg.isdigit() is False and seg is not ' ': #去除英文元素\n",
    "                #new_list.append(seg) #若在for loop裡用remove的話則會改變總長度\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#臉書content 斷字斷詞、清理\n",
    "oringnal_df['message'] = oringnal_df['message'].apply(lambda text : cut_words(text))\n",
    "oringnal_df['new'] = oringnal_df['message'].apply(lambda text : remove_stop_words(file_name,text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#只保留非hashtags的content內容\n",
    "def remain_instagram_post(text):\n",
    "    a = re.findall(r\"#(\\w+)\",text)\n",
    "    b = re.findall(r\"(\\w+)\",text)\n",
    "    c = list(set(b) - set(a))\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#備份content 與 呼叫remain_instagram_post動作\n",
    "oringnal_ig_df['post content copy'] = oringnal_ig_df['post content']\n",
    "oringnal_ig_df['post content'] = oringnal_ig_df['post content'].apply(lambda text : remain_instagram_post(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#將content陣列轉回字串型式\n",
    "oringnal_ig_df['post content'] = oringnal_ig_df['post content'].apply(lambda text : ' '.join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instagram 斷字斷詞、清理\n",
    "oringnal_ig_df['post content'] = oringnal_ig_df['post content'].apply(lambda text : cut_words(text))\n",
    "oringnal_ig_df['new content'] = oringnal_ig_df['post content'].apply(lambda text : remove_stop_words(file_name,text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#oringnal_ig_df['new content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#將oringnal_df['new'] form list to string\n",
    "oringnal_df['new_copy'] = oringnal_df['new']\n",
    "oringnal_df['new'] = oringnal_df['new'].apply(lambda text : ' '.join(text))\n",
    "#將oringnal_ig_df['new content'] form list to string\n",
    "oringnal_ig_df['new content'] = oringnal_ig_df['new content'].apply(lambda text : ' '.join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(oringnal_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update the index from 0 to finall\n",
    "oringnal_df.index = range(len(oringnal_df))\n",
    "oringnal_ig_df.index = range(len(oringnal_ig_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(oringnal_df),len(oringnal_ig_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#要將兩份文檔維度調整成一樣\n",
    "if len(oringnal_df)>len(oringnal_ig_df):\n",
    "    oringnal_df.drop(oringnal_df.index[len(oringnal_ig_df):], inplace=True,axis = 0)\n",
    "else:\n",
    "    oringnal_ig_df.drop(oringnal_ig_df.index[len(oringnal_df):], inplace=True,axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 進行LDA模型訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#後續要處理的文字部分存成corpus\n",
    "corpus=oringnal_df[\"new\"]\n",
    "ig_corpus=oringnal_ig_df[\"new content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cntVector = CountVectorizer(analyzer='word',token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\")\n",
    "ig_cntVector = CountVectorizer(analyzer='word',token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\")\n",
    "cntTf = cntVector.fit_transform(corpus)\n",
    "ig_cntTf = ig_cntVector.fit_transform(ig_corpus)\n",
    "# print (cntTf)\n",
    "# print (ig_cntTf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics = 10\n",
    "lda = LatentDirichletAllocation(n_components = n_topics, \n",
    "                                max_iter=50,\n",
    "                                learning_method='batch')\n",
    "docres = lda.fit_transform(cntTf) \n",
    "ig_docres = lda.fit_transform(ig_cntTf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (lda.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jensen_shannon_distance(p, q):\n",
    "    global Prm \n",
    "    \"\"\"\n",
    "    method to compute the Jenson-Shannon Distance \n",
    "    between two probability distributions\n",
    "    \"\"\"\n",
    "\n",
    "    # convert the vectors into numpy arrays in case that they aren't\n",
    "    p = np.array(p)\n",
    "    q = np.array(q)\n",
    "\n",
    "    # calculate m\n",
    "    m = (p + q) / 2\n",
    "\n",
    "    # compute Jensen Shannon Divergence\n",
    "    divergence = (scipy.stats.entropy(p, m) + scipy.stats.entropy(q, m)) / 2\n",
    "\n",
    "    # compute the Jensen Shannon Distance\n",
    "    distance = np.sqrt(divergence)\n",
    "    around = np.around(distance, decimals=4)\n",
    "    Prm = around.max()\n",
    "    \n",
    "    \n",
    "    return Prm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *得到 Prm 分數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prm = jensen_shannon_distance(docres,ig_docres)\n",
    "print(\"Prm : \",Prm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_top_words(model, feature_names, n_top_words):\n",
    "#     #打印每个主题下权重较高的term\n",
    "#     for topic_idx, topic in enumerate(model.components_):\n",
    "#         try:\n",
    "#             print (\"Topic #%d:\" % topic_idx)\n",
    "#             print (\" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "#         except Exception as e: print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_top_words=5\n",
    "# tf_feature_names = cntVector.get_feature_names()\n",
    "# print(tf_feature_names)\n",
    "# print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_top_words=50\n",
    "# tf_feature_names = ig_cntVector.get_feature_names()\n",
    "# print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity calculation module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instagram 斷字斷詞、清理\n",
    "# oringnal_ig_df['leavemessage content'] = oringnal_ig_df['leavemessage content'].apply(lambda text : cut_words(text))\n",
    "# oringnal_ig_df['leavemessage content']\n",
    "oringnal_ig_df['leavemessage content'] = oringnal_ig_df['leavemessage content'].astype(str)\n",
    "oringnal_ig_df['leavemessage content'] = oringnal_ig_df['leavemessage content'].apply(lambda text : cut_words(text))\n",
    "oringnal_ig_df['new leavemessage content'] = oringnal_ig_df['leavemessage content'].apply(lambda text : remove_stop_words(file_name,text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig_leavecontent_sentence = oringnal_ig_df['new leavemessage content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 進行SnowNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snownlp import SnowNLP\n",
    "#越接近1表示正面情緒\n",
    "#越接近0表示負面情緒"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#將oringnal_ig_df['new leavemessage content'] form list to string\n",
    "oringnal_ig_df['new leavemessage content'] = oringnal_ig_df['new leavemessage content'].apply(lambda text : ' '.join(text))\n",
    "ig_leavemessage_content = oringnal_ig_df['new leavemessage content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ig_leavemessage_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_score = 0\n",
    "sentence_count = 0\n",
    "for text in ig_leavemessage_content:\n",
    "    #print(text)\n",
    "    sentence_count+=1\n",
    "    try:\n",
    "        s = SnowNLP(text)\n",
    "    except Exception as e: pass\n",
    "\n",
    "    sentence_score += s.sentiments\n",
    "if sentence_score != 0:\n",
    "    ig_leavemessage_sentiments = sentence_score/sentence_count\n",
    "else:\n",
    "    print(\"sentence_score\",sentence_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig_content_likes = oringnal_ig_df['num of content likes'].mean()\n",
    "ig_content_likes = np.around(ig_content_likes,decimals=2)\n",
    "#print(ig_content_likes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(oringnal_ig_df['avg response'][0])\n",
    "# print(oringnal_ig_df['num of followers'][0])\n",
    "# print(oringnal_ig_df['num of tags'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 進行正歸化到區間 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pop_array = [[ig_leavemessage_sentiments,ig_content_likes,oringnal_ig_df['avg response'][0],oringnal_ig_df['num of followers'][0],oringnal_ig_df['num of tags'][0]]]\n",
    "Pop_array = [[ig_leavemessage_sentiments],[ig_content_likes],[oringnal_ig_df['avg response'][0]],[oringnal_ig_df['num of followers'][0]],[oringnal_ig_df['num of tags'][0]]]\n",
    "#print(Pop_array)\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler(copy=True, feature_range=(0, 1))\n",
    "x_minmax = min_max_scaler.fit_transform(Pop_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 得到Pop分數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pop = x_minmax.mean()\n",
    "print(\"Pop : \" , Pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity Calculation  Module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# 用戶發布的post數量。\n",
    "Ap = oringnal_ig_df['num of posts'][0]\n",
    "# 用戶最近一個月的post數量。\n",
    "Apm = oringnal_ig_df['one month posts'][0]\n",
    "# 用戶最新一次po文在多久以前。\n",
    "oringnal_ig_df['post_time'][0] = datetime.strptime(oringnal_ig_df['post_time'][0], \"%Y/%m/%d\")\n",
    "# print(type(oringnal_ig_df['post_time'][0]))\n",
    "# 用戶追蹤了多少人。\n",
    "Af = oringnal_ig_df['num of follows'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 進行正歸化到區間 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# 用戶最新一次po文在多久以前。由於是時間要素所以利用線性回歸方程式來正規化\n",
    "#現在時間\n",
    "now = datetime.datetime.now()\n",
    "if (now - oringnal_ig_df['post_time'][0]).days>10:\n",
    "    Apt = 0\n",
    "elif 0<=(now - oringnal_ig_df['post_time'][0]).days<=10:\n",
    "    Apt = -0.1*(now - oringnal_ig_df['post_time'][0]).days+1\n",
    "\n",
    "Pop_array = [[Ap],[Apm],[Af]]\n",
    "x_minmax = min_max_scaler.fit_transform(Pop_array)\n",
    "for number in x_minmax:\n",
    "    Act += float(number)\n",
    "Act += Apt\n",
    "Act /= 4\n",
    "print(\"Act : \" , Act)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Picture similarity module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 找出每篇instagram post 的hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#oringnal_ig_df['post content copy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#每篇post hashtags的部分\n",
    "oringnal_ig_df['post content copy'] = oringnal_ig_df['post content copy'].apply(lambda text : re.findall(r\"#(\\w+)\",text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(oringnal_ig_df['post content copy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oringnal_df['new'] = oringnal_df['new'].apply(lambda text : list(text))\n",
    "#oringnal_df['new_copy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oringnal_ig_df['post content copy'] = oringnal_ig_df['post content copy'].apply(lambda text : ' '.join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#臉書content 斷字斷詞、清理\n",
    "oringnal_ig_df['post content copy'] = oringnal_ig_df['post content copy'].apply(lambda text : cut_words(text))\n",
    "oringnal_ig_df['post content copy_stopwords'] = oringnal_ig_df['post content copy'].apply(lambda text : remove_stop_words(file_name,text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(oringnal_ig_df['post content copy_stopwords'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fb post 利用TextRank找出top 3關鍵字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#將陣列轉成str\n",
    "oringnal_df['new_copy'] = oringnal_df['new_copy'].apply(lambda text : ' '.join(text))\n",
    "# 將臉書content 透過textrank 只保留分數最高的三個詞，且不返回權重值\n",
    "oringnal_df['new_copy'] = oringnal_df['new_copy'].apply(lambda text : jieba.analyse.textrank(text, topK=3, withWeight=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#導入Word2vec模組\n",
    "from gensim.models import Word2Vec\n",
    "model_word2vec = Word2Vec.load(\"./word2vec-tutorial-master/word2vec.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 進行word2vec & cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#進行word2vec 回傳單詞向量\n",
    "def word2vec(word):\n",
    "    global model_word2vec\n",
    "    try:\n",
    "        model_word2vec[word]\n",
    "        return model_word2vec[word]\n",
    "    except Exception as e: pass\n",
    "    \n",
    "#計算cosine similarity\n",
    "def cosdis(v1, v2):\n",
    "    try:\n",
    "        cosine_similarity = np.dot(v1, v2)/(np.linalg.norm(v1)* np.linalg.norm(v2))\n",
    "        return cosine_similarity.item()\n",
    "    except Exception as e: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_picture_similarity(list_A,list_B):\n",
    "    global ig_fb_picture_similarity_score_list\n",
    "    \n",
    "    a = 0.0\n",
    "    threshold = 0.80     # if needed\n",
    "    for key in list_A:\n",
    "        for word in list_B:\n",
    "            try:\n",
    "                res = cosdis(word2vec(word), word2vec(key))\n",
    "                #從所有word2vec 從所有pair simlarity中取最大的score\n",
    "                try:\n",
    "                    if res >= a:\n",
    "                        a = res\n",
    "                except Exception as e: pass\n",
    "#                 print(\"The cosine similarity between : {} and : {} is: {}\".format(word, key, res*100))\n",
    "#                 if res > threshold:\n",
    "#                 print(\"Found a word with cosine distance > 80 : {} with original word: {}\".format(word, key))\n",
    "            except IndexError:\n",
    "                pass\n",
    "    ig_fb_picture_similarity_score_list.append(a)\n",
    "    return ig_fb_picture_similarity_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(oringnal_ig_df['post content copy_stopwords'])>= len(oringnal_df['new_copy']):\n",
    "    for i in range(len(oringnal_ig_df['post content copy_stopwords'])):\n",
    "        list_A = oringnal_ig_df['post content copy_stopwords'][i]\n",
    "        list_B = oringnal_df['new_copy'][i]\n",
    "        calculate_picture_similarity(list_A,list_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pic = sum(ig_fb_picture_similarity_score_list)/len(ig_fb_picture_similarity_score_list)\n",
    "print(\"Pic : \",Pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if model_choice == 0:\n",
    "#     print(\"model 0\")\n",
    "#     all_score = Prm*0.926 + Pic*0.926 + Pop*10.4 + Act*1.04\n",
    "# elif model_choice == 1:\n",
    "#     print(\"model 1\")\n",
    "#     all_score = Pic + Pop + Act\n",
    "# elif model_choice == 2:\n",
    "#     print(\"model 2\")\n",
    "#     all_score = Prm + Pop + Act\n",
    "# elif model_choice == 3:\n",
    "#     print(\"model 3\")\n",
    "#     all_score = Prm + Pic + Act\n",
    "# else:\n",
    "#     print(\"model 4\")\n",
    "#     all_score = Prm + Pic + Pop\n",
    "# print(\"all_score \" , all_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
